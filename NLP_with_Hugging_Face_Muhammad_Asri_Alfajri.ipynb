{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Let's try HuggingFace Transformers NLP Pipelines!\n"
      ],
      "metadata": {
        "id": "CztodpmQM11q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "6dtAhiTAMmYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a987437-25c4-4b8f-f21f-201c6ca5145b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "result = classifier(\n",
        "    \"This project is about developing an AI model to detect pests in chili plants using computer vision with CNN algorithms, aimed at helping farmers identify pest types and preventive measures.\",\n",
        "    candidate_labels=[\"agriculture\", \"computer vision\", \"machine learning\", \"CNN\"]\n",
        ")\n",
        "\n",
        "print(\"Sequence: \", result['sequence'])\n",
        "print(\"\\nClassification Results:\")\n",
        "for label, score in zip(result['labels'], result['scores']):\n",
        "    print(f\"- {label}: {score:.2f}\")"
      ],
      "metadata": {
        "id": "w3g0V_WTMpwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2355863c-244c-4873-cd65-79abb735dbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence:  This project is about developing an AI model to detect pests in chili plants using computer vision with CNN algorithms, aimed at helping farmers identify pest types and preventive measures.\n",
            "\n",
            "Classification Results:\n",
            "- machine learning: 0.40\n",
            "- computer vision: 0.33\n",
            "- CNN: 0.17\n",
            "- agriculture: 0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "result = classifier(\n",
        "    \"This project involves developing a YOLOv8 model to improve the accuracy of detecting dangerous objects in public spaces, aiming to enhance public safety through advanced object detection technology.\",\n",
        "    candidate_labels=[\"public safety\", \"security\", \"object detection\", \"computer vision\", \"deep learning\"]\n",
        ")\n",
        "\n",
        "print(\"Sequence: \", result['sequence'])\n",
        "print(\"\\nClassification Results:\")\n",
        "for label, score in zip(result['labels'], result['scores']):\n",
        "    print(f\"- {label}: {score:.2f}\")"
      ],
      "metadata": {
        "id": "iMxLGaXEehDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7287c25-fbd8-454f-de38-c812be9bce03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence:  This project involves developing a YOLOv8 model to improve the accuracy of detecting dangerous objects in public spaces, aiming to enhance public safety through advanced object detection technology.\n",
            "\n",
            "Classification Results:\n",
            "- public safety: 0.41\n",
            "- security: 0.24\n",
            "- object detection: 0.19\n",
            "- computer vision: 0.14\n",
            "- deep learning: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "result = classifier(\n",
        "    \"This project involves developing a machine learning regression model to predict CO2 emissions in Rwanda, focusing on identifying key environmental factors that contribute to emission levels and optimizing the model for accurate predictions.\",\n",
        "    candidate_labels=[\"regression\"]\n",
        ")\n",
        "\n",
        "print(\"Sequence: \", result['sequence'])\n",
        "print(\"\\nClassification Results:\")\n",
        "for label, score in zip(result['labels'], result['scores']):\n",
        "    print(f\"- {label}: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "jXpng5rlgVDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bdb80c9-20b5-438e-c148-dcdcb9f12107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence:  This project involves developing a machine learning regression model to predict CO2 emissions in Rwanda, focusing on identifying key environmental factors that contribute to emission levels and optimizing the model for accurate predictions.\n",
            "\n",
            "Classification Results:\n",
            "- regression: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "\n",
        "text_generator(\"In this training, you will learn essential skills in computer vision,\")"
      ],
      "metadata": {
        "id": "Qwkn1wZaNCxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5886d1a9-6756-4cdc-aa42-df06785e9583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this training, you will learn essential skills in computer vision, processing high-resolution images, image analysis, and data aggregation, plus you will also learn practical methods for creating an accurate, visually-realistic image.\\n\\nFormal Design\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text_generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "text_generator(\n",
        "    \"In this bootcamp, you will master data science skills such as\",\n",
        "    max_length=65,\n",
        "    num_return_sequences=4,\n",
        ")"
      ],
      "metadata": {
        "id": "drVV_RinNMws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9388013-1ede-49d4-b945-42f77a218ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this bootcamp, you will master data science skills such as how to keep our data secure at the same time, as well as work to expand its research into future business and applications. You can find a demo for the full process here. We are also doing a demonstration of our data project to get you hooked.'},\n",
              " {'generated_text': \"In this bootcamp, you will master data science skills such as deep learning, machine learning and machine learning and machine learning. The bootcamp starts at the start phase, so there won't be any downtime as a developer. All you need to do is install and install the Android SDK and you should be ready to go there\"},\n",
              " {'generated_text': 'In this bootcamp, you will master data science skills such as basic information science, security, network security, cryptography, and security to increase the likelihood of being exposed to hackers using a new system.\\n\\n\\n\\n\\nDownload\\nAll features are subject to change.\\nThis document contains most of the features you can find'},\n",
              " {'generated_text': 'In this bootcamp, you will master data science skills such as \"intercept\" and \"exploiting\" with your own data\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "generator(\"In my learning journey, I'm excited to explore new aspects of the\")\n"
      ],
      "metadata": {
        "id": "pv7R-U_gmGxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36581ba-ba6f-40f7-e7ee-4111ed9f1e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"In my learning journey, I'm excited to explore new aspects of the Internet and how we can improve privacy over time. In my last post I talked about ways in which we can better enhance our privacy:\\n\\nIn the early 90s, the\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "\n",
        "unmasker(\"During my internship as an AI Engineer, I learned about <mask> techniques in artificial intelligence.\", top_k=2)"
      ],
      "metadata": {
        "id": "-Ab97He7Dd0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69de9cfc-7fc9-4c23-dd68-43b1f728e19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.05707347393035889,\n",
              "  'token': 1337,\n",
              "  'token_str': ' various',\n",
              "  'sequence': 'During my internship as an AI Engineer, I learned about various techniques in artificial intelligence.'},\n",
              " {'score': 0.03942832723259926,\n",
              "  'token': 3319,\n",
              "  'token_str': ' advanced',\n",
              "  'sequence': 'During my internship as an AI Engineer, I learned about advanced techniques in artificial intelligence.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "\n",
        "ner(\"My name is Alfajri, and I am currently an AI Engineer at Infinite Learning in Batam.\")"
      ],
      "metadata": {
        "id": "H-uxwPRKDhpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52da0ef3-cf8a-416d-dc23-dd0b4babc106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.99501103,\n",
              "  'word': 'Alfajri',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99509513,\n",
              "  'word': 'Infinite Learning',\n",
              "  'start': 57,\n",
              "  'end': 74},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9898064,\n",
              "  'word': 'Batam',\n",
              "  'start': 78,\n",
              "  'end': 83}]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "context = \"As an AI Engineer, I focus on developing projects that implement artificial intelligence solutions in various domains.\"\n",
        "question = \"What is my role?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Answer: {result['answer']}\")"
      ],
      "metadata": {
        "id": "1SbkDlwfDlF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0d713f-16a2-48ce-9ead-45d75f67da75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: AI Engineer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "context = \"Alfajri is an AI Engineer at Infinite Learning, focusing on artificial intelligence projects, including waste management solutions and pest detection for farmers. He is currently studying D4 Teknik Mekatronika at Politeknik Negeri Batam.\"\n",
        "question = \"Who is Alfajri?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Answer: {result['answer']}\")\n"
      ],
      "metadata": {
        "id": "8Y1wD47GplfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9467cfb9-5e07-412a-a7e2-a70ca5b3ad5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: AI Engineer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "classifier(\"I am mad about the AI projects I am working on during my internship at Infinite Learning.\")"
      ],
      "metadata": {
        "id": "U3IZcIeAE41r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e0dbca-e188-43da-ad5c-1d56024c58d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9995119571685791}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    I've been actively involved in several innovative projects during my\n",
        "    internship as an AI Engineer at Infinite Learning. One notable project focuses on the\n",
        "    implementation of artificial intelligence in waste management in Batam, collaborating with\n",
        "    the Pelita Hijau Nusantara Foundation. This project goals is to develop efficient methods for\n",
        "    waste sorting and recycling, utilizing machine learning algorithms to enhance the management\n",
        "    of waste resources.\n",
        "\n",
        "    My another project is the development of a pest detection system for chili farmers,\n",
        "    which employs Convolutional Neural Networks (CNN) to identify various pests. This project not\n",
        "    only assists farmers in recognizing pest threats but also provides insights for effective\n",
        "    pest management strategies, ultimately contributing to improved crop yields.\n",
        "\n",
        "    Additionally, I have led a project on object detection, focusing on identifying missing\n",
        "    screws in production lines. This project highlights the application of AI in automation and\n",
        "    quality control processes within manufacturing, showcasing my ability to bridge technology\n",
        "    with practical industry needs.\n",
        "\n",
        "    Through these projects, I demonstrates a commitment to leveraging artificial\n",
        "    intelligence for practical applications, addressing real-world challenges, and contributing to\n",
        "    sustainable practices in my community.\n",
        "    \"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "rXSjHIImDptH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90b39a3-20dd-45cb-be4f-1c0b61ea4cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \" I've been actively involved in several innovative projects during my internship as an AI Engineer at Infinite Learning . One project focuses on the implementation of artificial intelligence in waste management in Batam, collaborating with the Pelita Hijau Nusantara Foundation . Another project is the development of a pest detection system for chili farmers,  which employs Convolutional Neural Networks (CNN) to identify various pests .\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-id-en\")\n",
        "\n",
        "text_to_translate = \"Saya sangat antusias untuk menerapkan AI dalam proyek yang saya kerjakan sebagai AI Engineer di Infinite Learning.\"\n",
        "result = translator(text_to_translate)\n",
        "\n",
        "print(result[0]['translation_text'])"
      ],
      "metadata": {
        "id": "Wxr6a3YYDtmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daccefe0-e56d-48d2-f363-1ff4baaed333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm very excited to apply AI to a project that I worked on as an AI Engineer at Infinite Learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis"
      ],
      "metadata": {
        "id": "FJ2DD_XpY6PC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Zero-Shot Classification**\n",
        "Berdasarkan yang saya pahami dari pembelajaran diatas, yaitu pipeline ini digunakan untuk mengklasifikasikan deskripsi proyek berdasarkan beberapa label tanpa pelatihan tambahan. Misalnya, pada proyek deteksi hama pada tanaman cabai dan proyek deteksi objek berbahaya yang saya coba gunakan, pipeline ini memberikan skor kepercayaan untuk menentukan relevansi deskripsi proyek dengan label yang telah ditentukan.\n",
        "\n",
        "#**Text Generation**\n",
        "Saya juga mempelajari pipeline text-generation yang mana pipeline ini bisa digunakan untuk menghasilkan teks, khususnya dengan model distilgpt2. Pipeline ini menghasilkan teks lanjutan berdasarkan prompt yang sudah saya diberikan, sehingga dapat digunakan untuk membangun contoh deskripsi proyek atau mengembangkan teks yang lebih kaya sesuai konteks yang diinginkan.\n",
        "\n",
        "#**Fill-Mask**\n",
        "Yang saya pahami setelah mencoba pipeline fill-mask, yaitu pipeline ini bisa digunakan untuk memprediksi kata yang hilang dalam kalimat. Ini memungkinkan prediksi kata yang sesuai dengan konteks kalimat, berguna untuk menyempurnakan deskripsi yang tidak lengkap atau mendapatkan ide kata yang relevan untuk melengkapi teks yang digunakan dalam proyek.\n",
        "\n",
        "#**Named Entity Recognition (NER)**\n",
        "Berdasarkan yang saya pahami, NER bekerja dengan mengelompokkan entitas yang dikenal dalam satu kategori, seperti nama tempat, organisasi, atau individu dalam teks. Pipeline ini dapat membantu dalam identifikasi elemen penting dalam deskripsi proyek, seperti lokasi atau subjek yang relevan.\n",
        "\n",
        "#**Question Answering (QA)**\n",
        "Saya juga memahami pipeline question-answering dengan model distilbert-base-cased-distilled-squad, yaitu dapat digunakan untuk menjawab pertanyaan berdasarkan konteks yang diberikan. Ini bisa digunakan untuk mendapatkan informasi spesifik dari teks proyek atau menjawab pertanyaan terkait deskripsi yang sudah ada.\n",
        "\n",
        "#**Sentiment Analysis**\n",
        "Pipeline ini digunakan untuk mengidentifikasi sentimen dalam teks. Hal ini mungkin berguna untuk menganalisis persepsi umum dari deskripsi proyek atau memahami aspek emosional dari proyek yang sedang dijelaskan.\n",
        "\n",
        "#**Summarization**\n",
        "Pipeline ini menyarikan teks panjang menjadi versi yang lebih ringkas. Dalam konteks proyek Anda, ini bisa membantu meringkas deskripsi proyek yang panjang sehingga poin-poin utamanya tetap tersampaikan secara ringkas.\n",
        "\n",
        "#**Translation**\n",
        "Pipeline translation menggunakan model Helsinki-NLP/opus-mt-id-en untuk menerjemahkan teks dari Bahasa Indonesia ke Bahasa Inggris. Ini mendukung konversi deskripsi proyek ke dalam bahasa lain, sehingga lebih mudah diakses atau dimengerti oleh audiens yang lebih luas."
      ],
      "metadata": {
        "id": "FjiCTJBaY6sQ"
      }
    }
  ]
}